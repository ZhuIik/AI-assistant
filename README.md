# üß† AI-Assistant (Fine-Tuned Gemma Edition)

AI-Assistant ‚Äî —ç—Ç–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (LLM).  
–ü—Ä–æ–µ–∫—Ç –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—á–∏—â–∞—Ç—å –ª–µ–∫—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª–∏ (Gemma-2, Mistral –∏ –¥—Ä.) —á–µ—Ä–µ–∑ LoRA-fine-tuning,  
–∏ –∑–∞–ø—É—Å–∫–∞—Ç—å —á–∞—Ç-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –±–µ–∑ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –≤–Ω–µ—à–Ω–∏–º API.

---

## üß© –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- üîπ **–û—á–∏—Å—Ç–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö** –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤ –∏ –ª–µ–∫—Ü–∏–π  
- üîπ **Fine-tuning –º–æ–¥–µ–ª–µ–π** (`Gemma-2-2B/9B`, `Mistral`) —Å –ø–æ–º–æ—â—å—é QLoRA  
- üîπ **–õ–æ–∫–∞–ª—å–Ω—ã–π —á–∞—Ç-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å** –±–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ (`chat_local.py`)  
- üîπ **–ì–∏–±–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**: –º–æ–∂–Ω–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å fine-tuning –∏ RAG (–ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –ª–µ–∫—Ü–∏–π)  
- üîπ **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ 4-–±–∏—Ç–Ω–æ–π –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ (bitsandbytes)** ‚Äî –æ–±—É—á–µ–Ω–∏–µ –¥–∞–∂–µ –Ω–∞ 8 GB GPU  
- üîπ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞** –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSONL

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

AI-ASSISTANT/
‚îú‚îÄ‚îÄ data/
‚îÇ ‚îú‚îÄ‚îÄ raw/ # –∏—Å—Ö–æ–¥–Ω—ã–µ –∞—É–¥–∏–æ –∏ —Ç–µ–∫—Å—Ç—ã
‚îÇ ‚îú‚îÄ‚îÄ cleaned/ # –æ—á–∏—â–µ–Ω–Ω—ã–µ –ª–µ–∫—Ü–∏–∏
‚îÇ ‚îú‚îÄ‚îÄ datasets/ # –≥–æ—Ç–æ–≤—ã–µ JSONL –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
‚îÇ ‚îî‚îÄ‚îÄ transcripts/ # —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç—ã Whisper
‚îú‚îÄ‚îÄ outputs/
‚îÇ ‚îî‚îÄ‚îÄ gemma_lectures_lora_v1/
‚îÇ ‚îú‚îÄ‚îÄ checkpoint-200/ # –≤–µ—Å–∞ –∏ –∫–æ–Ω—Ñ–∏–≥ –æ–±—É—á–µ–Ω–Ω–æ–π LoRA
‚îÇ ‚îî‚îÄ‚îÄ logs/ # –ª–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ scripts/
‚îÇ ‚îú‚îÄ‚îÄ finetune_lora.py # –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (QLoRA)
‚îÇ ‚îú‚îÄ‚îÄ chat_local.py # –ª–æ–∫–∞–ª—å–Ω—ã–π —á–∞—Ç —Å –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
‚îÇ ‚îú‚îÄ‚îÄ build_dataset.py # —Å–±–æ—Ä –ª–µ–∫—Ü–∏–π –≤ JSONL
‚îÇ ‚îî‚îÄ‚îÄ utils/ # –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md


---

## ‚öôÔ∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
git clone https://github.com/ZhuIik/AI-Assistant.git
cd AI-Assistant
python -m venv .venv
.\.venv\Scripts\activate   # Windows
# –∏–ª–∏ source .venv/bin/activate  # macOS/Linux
pip install -r requirements.txt

üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
1Ô∏è‚É£ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

–û—á–∏—Å—Ç–∏—Ç–µ –ª–µ–∫—Ü–∏–∏ –∏ —Å–æ–∑–¥–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç:

python scripts/build_dataset.py


‚Üí —Å–æ–∑–¥–∞—Å—Ç data/datasets/lectures_v1.jsonl

2Ô∏è‚É£ Fine-tuning –º–æ–¥–µ–ª–∏ (QLoRA)
python scripts/finetune_lora.py


–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –≤–µ—Å–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—Å—è –≤
outputs/gemma_lectures_lora_v1/checkpoint-XXX/

3Ô∏è‚É£ –ó–∞–ø—É—Å–∫ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —á–∞—Ç–∞
python scripts/chat_local.py


–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∑–∏—Ç –±–∞–∑–æ–≤—É—é Gemma-2-2B –∏ LoRA-–∞–¥–∞–ø—Ç–µ—Ä,
–ø–æ—Å–ª–µ —á–µ–≥–æ –º–æ–∂–Ω–æ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –Ω–∞–ø—Ä—è–º—É—é.

4Ô∏è‚É£ –ü–µ—Ä–µ–Ω–æ—Å –º–æ–¥–µ–ª–∏ –Ω–∞ –¥—Ä—É–≥–æ–π –∫–æ–º–ø—å—é—Ç–µ—Ä

–î–ª—è –ø–µ—Ä–µ–Ω–æ—Å–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å:

outputs/gemma_lectures_lora_v1/checkpoint-XXX/


–∏ —Ñ–∞–π–ª chat_local.py.
–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å–∫–∞—á–∏–≤–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å Hugging Face.

üß∞ –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
–ö–æ–º–ø–æ–Ω–µ–Ω—Ç	–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ
üêç Python 3.10+	–û—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫ –ø—Ä–æ–µ–∫—Ç–∞
üßÆ Transformers / PEFT / TRL	Fine-tuning –∏ —Ä–∞–±–æ—Ç–∞ —Å LLM
üíæ Bitsandbytes	4-–±–∏—Ç–Ω–∞—è –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è (QLoRA)
‚ö° Accelerate	–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
üéß Whisper	(–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ-–ª–µ–∫—Ü–∏–π
üìä Pandas / NumPy	–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö